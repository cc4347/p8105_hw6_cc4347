---
title: "p8105_hw6_cc4347"
author: "CC"
date: "11/24/2019"
output: github_document
---


# Problem 1: Child Birthweight Regression

## Load and Clean Dataset
```{r}
#Load libraries
  library(tidyverse)
  library(dplyr)
  library(modelr)

birth = read_csv("birthweight.csv") %>% 
  mutate(babysex = recode(babysex, 
                          "1" = "Male",
                          "2" = "Female"),
         fincome = fincome * 100,
         frace = recode(frace,
                        "1" = "White",
                        "2" = "Black",
                        "3" = "Asian",
                        "4" = "Puetro Rican",
                        "8" = "Other",
                        "9" = "Unknown"),
         mrace = recode(mrace,
                        "1" = "White",
                        "2" = "Black",
                        "3" = "Asian",
                        "4" = "Puetro Rican",
                        "8" = "Other"),
         malform = recode(malform, 
                          "0" = "Yes",
                          "1" = "No"
                          ),
         ) 

sum(is.na(birth))
```
Recoded variables for sex, race of both parents, and presence of malformations. There isn't any missing data.

## Regression Model for Birthweight
```{r}
model_1 = lm(bwt ~ babysex + bhead + blength + bwt + delwt + gaweeks + momage + parity + ppbmi + smoken + fincome + mrace, data = birth)

summary(model_1)

birth %>%
  modelr::add_residuals(model_1) %>%
  modelr::add_predictions(model_1) %>%
  ggplot(aes(x = pred, y = resid)) + geom_violin() + geom_hline(yintercept = 0, color = "peru")
```

Describe modeling process: I decided to create a model that considered many known possible underlying factors for low birthweight, which means that it adjusts for all of the variables included. Consequently, the result of this regression may be quite far from a crude estimate of birth weight assessed from a single (or few) variable(s) of interest. The plot of predicted values against residuals shows relatively constant variance from 0. Roughly it appears that most data points fall between -500-0 and 0-500 (on y-axis) with what appears to be a few outliers skewing the distribution in both a positive and negative direction (stronger skew in positive).

## Comparing Models

```{r}
# Model predictors: length at birth and gestational age (main effects)
model_2 = lm(bwt ~ blength + gaweeks, data = birth)

# Model head circumference, length, sex, and interactions between all variables
model_3 = lm(bwt ~ (bhead + blength + babysex)^3, data = birth)

# Compare all 3 models
crossv_mc(birth, 100)  %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
    mutate(model_1  = map(train, 
                     ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
                           gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
         
         model_2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         
         model_3 = map(train, ~lm(bwt ~ (bhead + blength + babysex)^3, data = .x))
         )%>%
  mutate(rmse_model1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y))) %>%
    select(starts_with("rmse")) %>% 
  pivot_longer(
      everything(),
      names_to = "model", 
      values_to = "rmse",
      names_prefix = "rmse_") %>% 
    mutate(model = fct_inorder(model)) %>% 
    ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```

By plotting all three models against their respective RMSE (root mean squared errors), we can see which is the best fit for the data. In this case, Model 1 exhibits the lowest RMSE, which indicates that the observed data points are closest to those predicted in this model.


# Problem 2: Weather Data Bootstrap

## Load Dataset
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

## Bootstrapping
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
boots = data_frame(
  strap_number = 1:5000,
  strap_sample = rerun(5000, boot_sample(weather_df))
)
boots_results = boots %>%
  mutate(models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
         results_glance =  map(models, broom::glance),
         result_tidy = map(models, broom::tidy)
         ) %>%
  select(-strap_sample, -models) %>%
  unnest() %>%
  select(strap_number, r.squared, term, estimate) %>%
  pivot_wider(names_from = "term",
              values_from = "estimate") %>%
  janitor::clean_names() %>%
  mutate(logB = log(intercept * tmin))

boots_results %>%
  summarise("R^2" = mean(r_squared),
            "Log(B0 * B1)" = mean(logB)) %>%
  knitr::kable(digits = 3)
r_squared= boots_results %>%
  ggplot(aes(x = r_squared)) +
  geom_histogram(alpha = 0.6, color = "peru") +
  xlab("Estimate R^2") 
log= boots_results %>%
  ggplot(aes(x = logB)) +
  geom_histogram(alpha = 0.6, color = "peru") +
  xlab("Log of Parameter")
r_squared
log
```

Visually both histograms appear to be Normally distributed, although there may be the slightly more left tail skew with the R^2 plot. That plot is centered at 0.911 while the Log(B0*B1) plot is centered at 2.013.

## Identify Quantiles (2.5% and 97.5%)
```{r}
quantile(pull(boots_results, r_squared), probs = c(.025, .975)) %>% 
    knitr::kable(digits = 3)
quantile(pull(boots_results, logB), probs = c(.025, .975)) %>% 
    knitr::kable(digits = 3)
```

